{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d82566327770a0841e6853d8bd154984",
     "grade": false,
     "grade_id": "cell-1da831f17b6dd41b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "\n",
    "**Read the `Instructions` notebook** before you start working on this problem set! It contains instructions on how to create the submission package. If you need more details on the *BayesNet* class, have a look at the **`BayesNet Introduction` notebook** of Problem Set 2.\n",
    "    \n",
    "</div>\n",
    "\n",
    "**General Remarks**:\n",
    "- Do not delete or add cells.\n",
    "- Store your results into the corresponding result variables or implement the provided function stubs.\n",
    "- Replace the placeholders `# YOUR CODE HERE` `raise NotImplementedError()` / `YOUR ANSWER HERE` with your code / answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b37947954259d35f2fcf85ce5dea0c65",
     "grade": false,
     "grade_id": "cell-d6e49c0f3b2294e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bayesian_network import BayesNet\n",
    "from utils import sample_forward, get_default_bayes_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f23539604b80a7872210ca382fdf8bb9",
     "grade": false,
     "grade_id": "cell-cbf36ef06ad975a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Parameter Learning\n",
    "\n",
    "In this problem, we will assume that a fixed dependency graph structure between variables is given and learn the parameters (the complete Conditional Probability Distribution Table (CPDT)) from a set of events. Furthermore, we will use log-likelihood to find a model structure that also generalizes to future data.\n",
    "    \n",
    "## ML Estimates for Conditional Distributions\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    Implement the <i>maximum_likelihood_estimate</i> function, which computes the Maximum Likelihood Estimate for the parameters of a discrete (conditional) probability distribution $ P(X \\mid \\mathit{pa}(X) )$, given a data set. (3 points)\n",
    "</div>\n",
    "\n",
    "`maximum_likelihood_estimate` takes  three parameters:\n",
    "- `data` is a NumPy array of shape `(num_samples, num_variables)`.\n",
    "- `variable_id` is the column index of the variable to estimate the distribution for.\n",
    "- `parent_ids` is a tuple containing the column indices of parent variables.\n",
    "\n",
    "`maximum_likelihood_estimate` must return one object:\n",
    "- A Maximum Likelihood Estimate (MLE) of the parameters in the form of a `np.ndarray`. The first dimension (index `0`) of the returned array must correspond to variable `variable_id`, the remaining dimensions must be sorted according to `parent_ids`. Altogether, tuple `(variable_id, ) + parent_ids` gives the mapping of dimensions to variables.\n",
    "\n",
    "**Hints**:\n",
    "- **Assume that all variables are binary.**\n",
    "- To count elements in a Numpy array, you simply loop over the data array.\n",
    "- Do not forget to use `keepdims=True` when normalizing your CPDT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b3a5b35a2ef85bd6cedaf8a28369a39",
     "grade": false,
     "grade_id": "cell-436ef56fc07b775c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def maximum_likelihood_estimate(data: np.ndarray, variable_id: int, parent_ids: tuple=tuple()):\n",
    "    \"\"\"\n",
    "    Estimates the conditional probability distribution of a (discrete) variable from data.\n",
    "    :param data:         data to estimate distribution from\n",
    "    :param variable_id:  column index corresponding to the variable we estimate the distribution for\n",
    "    :param parent_ids:   column indices of the variables the distribution is conditioned on\n",
    "    :returns:            estimated conditional probability distribution table\n",
    "    \"\"\"\n",
    "    \n",
    "    assert type(variable_id) == int\n",
    "    assert type(parent_ids) == tuple\n",
    "    \n",
    "    # mapping of axis to variable_id,\n",
    "    # e.g. the variable with id variable_ids[i] is on axis i of the CPDT\n",
    "    variable_ids = (variable_id,) + parent_ids\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    counts = np.zeros([2] * len(variable_ids))\n",
    "    \n",
    "    for x in data:\n",
    "        if len(parent_ids) > 0:\n",
    "            counts[x[variable_id], x[np.array(parent_ids)]] += 1\n",
    "        else:\n",
    "            counts[x[variable_id]] += 1\n",
    "    \n",
    "    cpdt = counts / counts.sum(0)\n",
    "    \n",
    "    return cpdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "adb291719ff2cfc195ae94a57e803778",
     "grade": true,
     "grade_id": "cell-1c8f099373bf6fc1",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "_A_, _B_, _C_, _D_, _E_ = 0, 1, 2, 3, 4\n",
    "# get the bayes net from the previous problem\n",
    "bayes_net = get_default_bayes_net()\n",
    "np.random.seed(0)\n",
    "# draw 100 samples\n",
    "data = sample_forward(bayes_net, 100)\n",
    "\n",
    "# get exact A from bayes net\n",
    "expected = bayes_net[_A_].pdt[:,0,0,0,0]\n",
    "# estimate A from the data\n",
    "actual = maximum_likelihood_estimate(data, _A_)\n",
    "# estimate should not be far off\n",
    "assert expected.shape == actual.shape, f'Shape of PDT was {actual.shape} but expected {expected.shape}.'\n",
    "assert np.allclose(expected, actual, atol=0.05), f'Expected {expected} but got {actual} instead.'\n",
    "\n",
    "# get exact B_A from bayes net\n",
    "expected = bayes_net[_B_].pdt[:,:,0,0,0].T\n",
    "# estimate B_A from data\n",
    "actual = maximum_likelihood_estimate(data, _B_, (_A_,))\n",
    "# estimate should not be far off\n",
    "assert expected.shape == actual.shape, f'Shape of CPDT was {actual.shape} but expected {expected.shape}.'\n",
    "assert np.allclose(expected, actual, atol=0.05), f'Expected {expected} but got {actual} instead.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46db2b9346b2d9f13540394cec9b1adb",
     "grade": false,
     "grade_id": "cell-266284793d5b1fa8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### The Log-Likelihood Function\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    Implement the <i>log_likelihood</i> function, which computes the log-likelihood $\\mathcal{L}(\\mathcal{M} : \\mathcal{D})$ of a model (BayesNet) realtive to a data set. (3 points)\n",
    "</div>\n",
    "\n",
    "`log_likelihood`takes  two parameters:\n",
    "- `data` is a NumPy array of shape `(num_samples, num_variables)`.\n",
    "- `bayes_net` a BayesNet object representing the model $\\mathcal{M}$ (containing already estimated CPDTs).\n",
    "\n",
    "`log_likelihood` must return one object:\n",
    "- The log-likelihood of the model given the data (i.e., a floating-point number $\\leq 0$).\n",
    "\n",
    "Hint:\n",
    "- Recall that iterating over the variables in the BayesNet is super easy: `for variable in bayes_net: ...`.\n",
    "- The 1D probability distribution of variable $X$ given its parents $\\mathit{pa}(X)$, $P(X \\mid \\mathit{pa}(X))$, can be obtained by passing the random event to the variable, i.e., `variable(data[i])`.\n",
    "- Use the natural logarithm for your computations, i.e. `np.log`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58fab9bc06fd7e4e4bb42b98b9b97e6d",
     "grade": false,
     "grade_id": "cell-05bb2766b425e4ac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def log_likelihood(data: np.ndarray, bayes_net: BayesNet) -> float:\n",
    "    \"\"\"\n",
    "    Computes the log-likelihood of a given Bayesian network relative to the data.\n",
    "    :param data:      data to compute the log-likelihood relative to.\n",
    "    :param bayes_net: Bayesian network model.\n",
    "    :returns:         the log-likelihood of the Bayesian network relative to the data.\n",
    "    \"\"\"    \n",
    "\n",
    "    ll = 0\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    for x in data:\n",
    "        for variable in bayes_net:\n",
    "            distribution = variable(x)\n",
    "            ll += np.log(distribution[x[variable.id]])\n",
    "    \n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8999f49ba507354e64ffa04c3547fb9c",
     "grade": true,
     "grade_id": "cell-fb8f52c535549516",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "# get the bayes net from the previous problem\n",
    "bayes_net = get_default_bayes_net()\n",
    "np.random.seed(0)\n",
    "# draw 100 samples\n",
    "data = sample_forward(bayes_net, 100)\n",
    "\n",
    "# expected log-likelihood\n",
    "expected = -215.9\n",
    "# actual log-likelihood\n",
    "actual = log_likelihood(data, bayes_net)\n",
    "\n",
    "# must be close\n",
    "assert isinstance(actual, float), f'Log Likelihood should be of type `float`, but got {type(actual)}.'\n",
    "assert np.isclose(expected, actual, atol=0.1), f'Expected Log-Likelihood {expected}, but got {actual}.'\n",
    "\n",
    "\n",
    "# remove unused variables\n",
    "del data\n",
    "del bayes_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding a Model for Strokes   \n",
    "\n",
    "After watching hours of medical dramas on television, a medicine freshman tries to figure out the perfect prediction model for strokes. Some of her computer science colleagues told her about how Bayesian networks can be used for symptom diagnosis, so she decides to model her ideas using this technique. In order to find out the (conditional) probability distributions, she needs to find a lot of training examples. One of her computer science colleagues cracks the computer system of the university clinic and copies a lot of medical patient data. \n",
    "\n",
    "All variables in this example are boolean (false=0 or true=1). The data for this assignment is stored in two text files, \"train.txt\" and \"test.txt\". They contain 500 (train) and 5000 (test) samples of the following five random variables:\n",
    "\n",
    " - Column 0: A ... Alcoholism\n",
    " - Column 1: H ... High Blood Pressure\n",
    " - Column 2: S ... Stroke\n",
    " - Column 3: C ... Confusion\n",
    " - Column 4: V ... Vertigo\n",
    " \n",
    "First, she decides to try out the following, very simple model:\n",
    "    \n",
    "<img style='width:100%;  max-width:400px;' src=\"img/bn_mod1.svg\">\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    Estimate the (conditional) probability tables of Model 1 and compute the log-likelihood of Model 1 given the training data. (1 point)\n",
    "</div>\n",
    "\n",
    "Store the estimated CPDTs into the provided variables.\n",
    "\n",
    "**Hints**:\n",
    "- Use the two functions you implemented above (`maximum_likelihood_estimate` and `log_likelihood`)!\n",
    "- The training data is stored in variable `train`.\n",
    "- `_A_, _H_, _S_, _C_, _V_` hold the column indices (= IDs) of the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "394a9a0ed698da10cf72dc84b84b447e",
     "grade": false,
     "grade_id": "cell-11b996647bc6f74c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "_A_, _H_, _S_, _C_, _V_ = 0, 1, 2, 3, 4\n",
    "train = np.loadtxt('data/train.txt', dtype=int)\n",
    "\n",
    "A, H, S, C, V = None, None, None, None, None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "import itertools\n",
    "\n",
    "def conditional_distribution(data, variable_id, parent_ids=[]):\n",
    "    distribution = np.zeros([2] * (len(parent_ids) + 1))\n",
    "    \n",
    "    for permutation in itertools.product([0, 1], repeat=len(parent_ids) + 1):\n",
    "        if len(parent_ids) == 0:\n",
    "            matching_values = data\n",
    "        else:\n",
    "            matching_values = data[np.logical_and.reduce([data[:, parent_id] == value for parent_id, value in zip(parent_ids, permutation[1:])])]\n",
    "        \n",
    "        distribution[permutation] = np.count_nonzero(matching_values[:, variable_id] == permutation[0]) / len(matching_values)\n",
    "    \n",
    "    return distribution\n",
    "\n",
    "A = conditional_distribution(train, _A_)\n",
    "H = conditional_distribution(train, _H_)\n",
    "S = conditional_distribution(train, _S_)\n",
    "C = conditional_distribution(train, _C_)\n",
    "V = conditional_distribution(train, _V_)\n",
    "\n",
    "# begin sanity check\n",
    "assert np.allclose(A.sum(axis=0), 1), '`A` must be a well-formed PDT (sum to 1)'\n",
    "assert np.allclose(H.sum(axis=0), 1), '`H` must be a well-formed PDT (sum to 1)'\n",
    "assert np.allclose(S.sum(axis=0), 1), '`S` must be a well-formed PDT (sum to 1)'\n",
    "assert np.allclose(C.sum(axis=0), 1), '`C` must be a well-formed PDT (sum to 1)'\n",
    "assert np.allclose(V.sum(axis=0), 1), '`V` must be a well-formed PDT (sum to 1)'\n",
    "# end sanity check\n",
    "\n",
    "bayes_net_1 = BayesNet(\n",
    "    (A, (_A_,)),\n",
    "    (H, (_H_,)),\n",
    "    (S, (_S_,)),\n",
    "    (C, (_C_,)),\n",
    "    (V, (_V_,))\n",
    ")\n",
    "\n",
    "tr_log_likelihood_1 = log_likelihood(train, bayes_net_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e5c13f324f87e7e5a52e3707414c816",
     "grade": true,
     "grade_id": "cell-b30990c4827845f9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "assert -1300 < tr_log_likelihood_1 < -1100, f'Expected log-likelihood to be in [-1300, -1100] but got {tr_log_likelihood_1}.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not satisfied with the results, our freshman decides that Model 1 is probably too simple to represent the real world. She adds some edges to the model and tries again:\n",
    "\n",
    "<img  style='width:100%;  max-width:400px;' src=\"img/bn_mod2.svg\">\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    Estimate the (conditional) probability tables of Model 2 and compute the log-likelihood of Model 2 given the training data. (1 point)\n",
    "</div>\n",
    "\n",
    "Store the estimated CPDTs into the provided variables. The dimensions of the CPDT must be sorted according to the naming of the variable, e.g., in C_AS, dimension 0 corresponds to C, dimension 1 to A, and dimension 2 to S.\n",
    "\n",
    "**Hints**:\n",
    "- Use the two functions you implemented above (`maximum_likelihood_estimate` and `log_likelihood`)!\n",
    "- The training data is stored in variable `train`. \n",
    "- `_A_, _H_, _S_, _C_, _V_` hold the column indices (= IDs) of the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68f39fe9e75f69455531145039c7c3cd",
     "grade": false,
     "grade_id": "cell-adce166a4d080cf7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "_A_, _H_, _S_, _C_, _V_ = 0, 1, 2, 3, 4\n",
    "train = np.loadtxt('data/train.txt', dtype=int)\n",
    "\n",
    "A, H_A, S_H, C_AS, V_S = None, None, None, None, None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "A = conditional_distribution(train, _A_)\n",
    "H_A = conditional_distribution(train, _H_, [_A_])\n",
    "S_H = conditional_distribution(train, _S_, [_H_])\n",
    "C_AS = conditional_distribution(train, _C_, [_A_, _S_])\n",
    "V_S = conditional_distribution(train, _V_, [_S_])\n",
    "\n",
    "# begin sanity check\n",
    "assert np.allclose(A.sum(axis=0), 1), '`A` must be a well-formed PDT (sum to 1)'\n",
    "assert np.allclose(H_A.sum(axis=0), 1), '`H_A` must be a well-formed CPDT (sum to 1)'\n",
    "assert np.allclose(S_H.sum(axis=0), 1), '`S_H` must be a well-formed CPDT (sum to 1)'\n",
    "assert np.allclose(C_AS.sum(axis=0), 1), '`C_AS` must be a well-formed CPDT (sum to 1)'\n",
    "assert np.allclose(V_S.sum(axis=0), 1), '`V_S` must be a well-formed CPDT (sum to 1)'\n",
    "# end sanity check\n",
    "\n",
    "bayes_net_2 = BayesNet(\n",
    "    (A, (_A_,)),\n",
    "    (H_A, (_H_,_A_)),\n",
    "    (S_H, (_S_,_H_)),\n",
    "    (C_AS, (_C_,_A_,_S_)),\n",
    "    (V_S, (_V_,_S_))\n",
    ")\n",
    "\n",
    "tr_log_likelihood_2 = log_likelihood(train, bayes_net_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2af6a03c06876f87767cb7e4cd7803f9",
     "grade": true,
     "grade_id": "cell-aee49c763a9fe1a7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "assert -1300 < tr_log_likelihood_2 < -1100, f'Expected log-likelihood to be in [-1300, -1100] but got {tr_log_likelihood_2}.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Finally, she decides to try out an even more complex model:\n",
    "\n",
    "<img  style='width:100%;  max-width:400px;' src=\"img/bn_mod3.svg\">\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    Estimate the (conditional) probability tables of Model 3 and compute the log-likelihood of Model 3 given the training data. (1 point)\n",
    "</div>\n",
    "\n",
    "Store the CPDTs into the provided variables. The dimensions of the CPDT must be sorted according to the naming of the variable, e.g., in C_AS, dimension 0 corresponds to C, dimension 1 to A, and dimension 2 to S.\n",
    "\n",
    "**Hint**:\n",
    "- Use the two functions you implemented above (`maximum_likelihood_estimate` and `log_likelihood`)!\n",
    "- The training data is stored in variable `train`. \n",
    "- `_A_, _H_, _S_, _C_, _V_` hold the column indices (= IDs) of the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "959102a7dfb4782cdf6d214e6bcd8096",
     "grade": false,
     "grade_id": "cell-385934a752ed9259",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "_A_, _H_, _S_, _C_, _V_ = 0, 1, 2, 3, 4\n",
    "train = np.loadtxt('data/train.txt', dtype=int)\n",
    "\n",
    "A, H_A, S_AH, C_AS, V_CS = None, None, None, None, None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "A = conditional_distribution(train, _A_)\n",
    "H_A = conditional_distribution(train, _H_, [_A_])\n",
    "S_AH = conditional_distribution(train, _S_, [_A_, _H_])\n",
    "C_AS = conditional_distribution(train, _C_, [_A_, _S_])\n",
    "V_CS = conditional_distribution(train, _V_, [_C_, _S_])\n",
    "\n",
    "# begin sanity check\n",
    "assert np.allclose(A.sum(axis=0), 1), '`A` must be a well-formed PDT (sum to 1)'\n",
    "assert np.allclose(H_A.sum(axis=0), 1), '`H_A` must be a well-formed CPDT (sum to 1)'\n",
    "assert np.allclose(S_AH.sum(axis=0), 1), '`S_AH` must be a well-formed CPDT (sum to 1)'\n",
    "assert np.allclose(C_AS.sum(axis=0), 1), '`C_AS` must be a well-formed CPDT (sum to 1)'\n",
    "assert np.allclose(V_CS.sum(axis=0), 1), '`V_CS` must be a well-formed CPDT (sum to 1)'\n",
    "# end sanity check\n",
    "\n",
    "bayes_net_3 = BayesNet(\n",
    "    (A, (_A_,)),\n",
    "    (H_A, (_H_,_A_)),\n",
    "    (S_AH, (_S_,_A_,_H_)),\n",
    "    (C_AS, (_C_,_A_,_S_)),\n",
    "    (V_CS, (_V_,_C_,_S_))\n",
    ")\n",
    "\n",
    "tr_log_likelihood_3 = log_likelihood(train, bayes_net_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7eebb14c5a47dc774af9cbeb4efde9d6",
     "grade": true,
     "grade_id": "cell-0847b76132961219",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "assert -1300 < tr_log_likelihood_3 < -1100, f'Expected log-likelihood to be in [-1300, -1100] but got {tr_log_likelihood_3}.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5c5eab45c2c49828b2a2ee43e3a1c425",
     "grade": false,
     "grade_id": "cell-60eaec1dda1e7b09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Compare Train Log-Likelihoods\n",
    "\n",
    "Compare the log-likelihoods of the training data given the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae46f32357d5c58a722e4046bf08c6f0",
     "grade": false,
     "grade_id": "cell-14898c94ac010e16",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logP(train|M1) = -1214.6425612469914\n",
      "logP(train|M2) = -1175.123630631206\n",
      "logP(train|M3) = -1174.6821826610374\n"
     ]
    }
   ],
   "source": [
    "print('logP(train|M1) = {}'.format(tr_log_likelihood_1))\n",
    "print('logP(train|M2) = {}'.format(tr_log_likelihood_2))\n",
    "print('logP(train|M3) = {}'.format(tr_log_likelihood_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e03a73ba8a086daf66f99b88858caf75",
     "grade": false,
     "grade_id": "cell-913efb638a138834",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Compare Test Log-Likelihoods\n",
    "\n",
    "The computer science colleague manages to obtain more data from the clinic's network and stores it in the file `test.txt`. Our medicine freshman is eager to try the models on the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40943b2167f1d254ec65c8bb3ae9584b",
     "grade": false,
     "grade_id": "cell-ce96bfd55367a74f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test = np.loadtxt('data/test.txt', dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae2f9a3fc920e916304dd0cf5c3cbd66",
     "grade": false,
     "grade_id": "cell-6fbfecbadd2e85f9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "She computes the log-likelihood of the test data for each of the three models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce2d838d52c5ec2698eecbf58224ce14",
     "grade": false,
     "grade_id": "cell-7405d51a161fef12",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logP(test|M1) = -11911.976345359737\n",
      "logP(test|M2) = -11565.57072258751\n",
      "logP(test|M3) = -11571.024593414042\n"
     ]
    }
   ],
   "source": [
    "te_log_likelihood_1 = log_likelihood(test, bayes_net_1)\n",
    "te_log_likelihood_2 = log_likelihood(test, bayes_net_2)\n",
    "te_log_likelihood_3 = log_likelihood(test, bayes_net_3)\n",
    "\n",
    "print('logP(test|M1) = {}'.format(te_log_likelihood_1))\n",
    "print('logP(test|M2) = {}'.format(te_log_likelihood_2))\n",
    "print('logP(test|M3) = {}'.format(te_log_likelihood_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2a5bb1f4231b63dee57766f4185be7e2",
     "grade": false,
     "grade_id": "cell-c6cc8633bf6db812",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Answer the following questions by storing True or False into the provided variables! (0.5 points each)\n",
    "</div>\n",
    "\n",
    "1. In maximum likelihood estimation, variables with a large number of parents might lead to unspecified distributions. \n",
    "2. A higher (log-)likelihood on the training data always translates to better performance on unseen future data.\n",
    "3. (Log-)likelihood describes the probability of the model as a function of the data.\n",
    "4. Adding an edge to a Bayesian network will never result in a lower likelihood on the training data.\n",
    "5. Out of the three tested models, model 3 is the best choice.\n",
    "6. If we use a uniform prior over model parameters, the Maximum A Posteriori (MAP) estimate is equal to the Maximum Likelihood (ML) estimate, i.e., $\\hat{\\theta}_{MAP} = \\hat{\\theta}_{ML}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce4dce6b47f80e7e81311a20adbd23fc",
     "grade": false,
     "grade_id": "cell-6f9bf6499414a76b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "results = dict()\n",
    "results['1'] = False\n",
    "results['2'] = True\n",
    "results['3'] = False\n",
    "results['4'] = True\n",
    "results['5'] = True\n",
    "results['6'] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b4b7a9d67060b525f404d61e65601f1",
     "grade": true,
     "grade_id": "cell-76a0a7b9705aa05b",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this is a hidden test; don't remove ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "449ffd048438dde7ca55007cebbacfa6",
     "grade": true,
     "grade_id": "cell-08189240e67f8b93",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this is a hidden test; don't remove ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23c5ec35af84ee0afd64900dab9ae672",
     "grade": true,
     "grade_id": "cell-a7dfa173d9aa0bb1",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this is a hidden test; don't remove ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "139d0117e2eb0e0f5985385b8d083f98",
     "grade": true,
     "grade_id": "cell-bfa0b4282b5a6f5e",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this is a hidden test; don't remove ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aeeeef6f9bd93c9fa059f59c96016bfe",
     "grade": true,
     "grade_id": "cell-acfc3eaf64664987",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this is a hidden test; don't remove ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93497c643ec314f6e6a7c2b876c5def9",
     "grade": true,
     "grade_id": "cell-02de447076067cb8",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this is a hidden test; don't remove ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
